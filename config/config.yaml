optuna:
  n_trials: 50  # Number of trials for hyperparameter optimization.

model:
  backbone: "fasterrcnn_resnet50_fpn_v2"  # Backbone model for feature extraction.
  num_classes: 4  # Number of classes (10 + 1 for background).
  pretrained: true  # Whether to use pretrained weights for the backbone.

training:
  num_workers: 4
  batch_size: 16  # Batch size for training.
  epochs: 5  # Number of training epochs.
  save_dir: "./checkpoints"  # Directory to save model checkpoints.
  learning_rate: 0.001  # Initial learning rate.
  optimizer: "adam"  # Optimizer to use (Adam by default).
  scheduler: "step"  # Learning rate scheduler type (e.g., step, cosine, etc.).
  step_size: 10  # Step size for step scheduler.
  gamma: 0.1  # Learning rate decay factor for the scheduler.
  warmup_epochs: 5  # Number of warm-up epochs (optional, can be added later).
  weight_decay: 1e-4  # Weight decay regularization (optional).

data:
  train:
    root_dir: "dataset/data/train"
    annotations: "dataset/data/train/annotations.json"
  val:
    root_dir: "dataset/data/val"
    annotations: "dataset/data/val/annotations.json"
  train_split: 0.8  # Fraction of the dataset to use for training.
  val_split: 0.2  # Fraction of the dataset to use for validation (optional).
  shuffle: true  # Whether to shuffle the dataset before splitting.
  augmentation:  # Placeholder for dataset augmentation strategies.
    - "RandomHorizontalFlip"  # Example augmentation.
    - "RandomCrop"  # Another placeholder for random crop.
    # Add more augmentations as needed, for example: "RandomRotation", "ColorJitter", etc.
